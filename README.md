# TelecomX ‚Äì Predicci√≥n de Churn (Customer Cancellation)

![status](https://img.shields.io/badge/status-active-brightgreen) ![python](https://img.shields.io/badge/python-3.10%2B-blue) ![sklearn](https://img.shields.io/badge/scikit--learn-1.x-orange)

Proyecto de *Machine Learning* para **predecir cancelaci√≥n de clientes (churn)** en una telco, con enfoque en:

* pipeline reproducible de preparaci√≥n de datos,
* entrenamiento de **dos modelos** (uno con normalizaci√≥n, otro sin),
* evaluaci√≥n con m√©tricas robustas a desbalance,
* interpretaci√≥n/variables clave y **acciones de retenci√≥n**.

> **Churn observado**: \~25.72% (moderado desbalance).
> **Modelos**: KNN (con escalado) y Random Forest (sin escalado).

---

## üìÅ Estructura del repositorio

```
.
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ Telecom_2.ipynb                # Notebook principal (EDA, encoding, modelado)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ TelecomX_Data.json             # Original expandido/curado (si aplica)
‚îÇ   ‚îú‚îÄ‚îÄ TelecomX_Data_encoded.json     # One-Hot Encoding aplicado
‚îÇ   ‚îî‚îÄ‚îÄ TelecomX_Data_scaled.json      # Escalado (StandardScaler) para modelos sensibles
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ train_models.py                # Script Colab-ready para entrenar KNN y RF
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ metrics_summary.json           # M√©tricas comparativas (test)
‚îÇ   ‚îú‚îÄ‚îÄ knn_confusion_matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ knn_roc.png
‚îÇ   ‚îú‚îÄ‚îÄ knn_pr.png
‚îÇ   ‚îú‚îÄ‚îÄ rf_confusion_matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ rf_roc.png
‚îÇ   ‚îú‚îÄ‚îÄ rf_pr.png
‚îÇ   ‚îî‚îÄ‚îÄ rf_feature_importances_top25.png
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ model_knn.joblib               # Pipeline/estimador KNN entrenado
‚îÇ   ‚îî‚îÄ‚îÄ model_random_forest.joblib     # Modelo RandomForest entrenado
‚îú‚îÄ‚îÄ REPORT.md                          # Informe ejecutivo de resultados y recomendaciones
‚îî‚îÄ‚îÄ README.md                          # Este archivo
```

> **Nota**: Las rutas pueden variar seg√∫n ejecutes en **Google Colab** (`/content/...`) o localmente (`./data`, `./outputs`, etc.).

---

## üìä Datos

* Fuente de referencia: dataset de churn tipo Telco (estructura anidada con `customer`, `phone`, `internet`, `account`).
* Pasos de preparaci√≥n:

  1. **Expansi√≥n** de campos anidados (json ‚Üí columnas planas).
  2. **One‚ÄëHot Encoding** de todas las categ√≥ricas.
  3. Eliminaci√≥n de **varianza cero** (ruido tras OHE masivo).
  4. **Estandarizaci√≥n** (solo para pipelines que lo requieren, p. ej., KNN).
* **Target**: `Churn_Yes` (binaria: 1=se va, 0=permanece).

---

## ‚ö°Ô∏è Quickstart

### Opci√≥n A) Google Colab

1. Sube `TelecomX_Data_encoded.json` (y `TelecomX_Data_scaled.json` si ya lo generaste) a `/content/`.
2. Abre el notebook `notebooks/Telecom_2.ipynb` o copia el script de `src/train_models.py` en una celda.
3. Ejecuta todo. Los resultados se guardar√°n en `/content/outputs` y los modelos en `/content/models`.

### Opci√≥n B) Local (venv)

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
python src/train_models.py --data data/TelecomX_Data_encoded.json \
                           --outputs outputs --models models
```

Par√°metros comunes:

```bash
--data <ruta al json codificado>
--test-size 0.2
--random-state 42
--cv-splits 5
--n-estimators 400         # para RandomForest
```

---

## üß† Modelado

* **KNN** (con `StandardScaler` en `Pipeline`): *grid search* de `n_neighbors`, `weights`, `p` (Manhattan/Euclidiana).
* **Random Forest** (sin escalado): `class_weight='balanced'`, 400 √°rboles.
* Divisi√≥n **estratificada** 80/20.
* **M√©tricas**: Accuracy, ROC‚ÄëAUC, PR‚ÄëAUC, Precision, Recall, F1.
* Gr√°ficos: matrices de confusi√≥n, curvas ROC y PR; **importancias** (RF).

Ejemplo (salidas):

```json
{
  "knn": {"accuracy": 0.85, "roc_auc": 0.88, "ap": 0.62},
  "random_forest": {"accuracy": 0.87, "roc_auc": 0.91, "ap": 0.66},
  "n_features_after_vt": 3120
}
```

---

## üìà Interpretaci√≥n & Negocio

* Factores t√≠picos asociados a mayor churn: **contrato mes a mes**, **tenure bajo**, **electronic check**, **cargos mensuales altos**, **sin tech support/online security**.
* Ver `outputs/rf_feature_importances_top25.png` para tu *Top‚ÄëN* real.
* Recomendaciones: upgrades por permanencia, onboarding proactivo, incentivos a medios de pago autom√°ticos, bundles/paquetes, trials de servicios de soporte.

---

## üîÅ Reproducibilidad

* Fijar `random_state=42` en splits/modelos.
* Mantener **misma versi√≥n** de librer√≠as (`requirements.txt`).
* Usar **validaci√≥n estratificada** y separar **train/test** por cliente.

---

## üß™ Predicci√≥n con modelos guardados

```python
import joblib, pandas as pd
X_nuevo = pd.read_json("data/TelecomX_Data_encoded.json").drop(columns=["Churn_Yes"], errors="ignore")
rf = joblib.load("models/model_random_forest.joblib")
proba = rf.predict_proba(X_nuevo)[:,1]  # probabilidad de churn
```

> Ajusta el **umbral** (p. ej., 0.35‚Äì0.5) seg√∫n tu curva costo‚Äëbeneficio.

---

* Dataset de referencia tipo **Telco Customer Churn**.
* Comunidad de **scikit‚Äëlearn** por las herramientas de modelado y evaluaci√≥n.
